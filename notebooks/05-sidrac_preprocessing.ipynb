{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b7b72e3",
   "metadata": {},
   "source": [
    "# Preprocessing Sidrac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fee873",
   "metadata": {},
   "source": [
    "The Sidrac is a prose text and needed some extra preprocessing. This notebook is not really relevant for the analysis but it is included to be complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af531243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def extract_text_from_xml(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    texts = []\n",
    "\n",
    "    # Recursive function to extract all text within <text> elements\n",
    "    def extract_text(element):\n",
    "        if element.tag == \"text\":\n",
    "            texts.append(element.text.strip() if element.text else \"\")\n",
    "        for child in element:\n",
    "            if child.tail:\n",
    "                texts.append(child.tail.strip())\n",
    "\n",
    "    extract_text(root)\n",
    "\n",
    "    return \"\\n\".join(t for t in texts if t)  # Join all extracted texts\n",
    "\n",
    "# Usage example\n",
    "xml_file = \"../sidrac/sidrac_cdrom.xml\"  # Replace with your XML file path\n",
    "extracted_text = extract_text_from_xml(xml_file)\n",
    "print(extracted_text)\n",
    "\n",
    "#l p head hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15905ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         word pos lemma\n",
      "0    PROLOGHE          \n",
      "1           $          \n",
      "2       Dicke          \n",
      "3      hebbic          \n",
      "4         die          \n",
      "5        gene          \n",
      "6   bescouden          \n",
      "7           $          \n",
      "8         Die          \n",
      "9         hem          \n",
      "10        ane          \n",
      "11        die          \n",
      "12      boeke          \n",
      "13     houden          \n",
      "14          $          \n",
      "15       Daer          \n",
      "16         sy          \n",
      "17      clene          \n",
      "18    profijt          \n",
      "19       inne          \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# Function to process XML files\n",
    "def process_xml_to_tsv(xml_filepath, tsv_filepath):\n",
    "    \"\"\"Extract tokens from an XML file and save them to a TSV file with empty 'pos' and 'lemma' columns.\"\"\"\n",
    "    tree = etree.parse(xml_filepath)\n",
    "\n",
    "    words = []\n",
    "    previous_verse = None  # To track the last added verse\n",
    "\n",
    "    # List of elements to process in order of appearance\n",
    "    elements_to_extract = ['l', 'p', 'head', 'hi']\n",
    "\n",
    "    # Iterate over the XML tree while preserving element order\n",
    "    for element in tree.iter():\n",
    "        if element.tag in elements_to_extract:\n",
    "            # Extract all text content from the element, including nested text\n",
    "            full_text = ''.join(element.itertext()).strip()\n",
    "\n",
    "            # Remove tokens like (B:) where B can be any combination of letters\n",
    "            cleaned_text = re.sub(r'\\([A-Za-z]+:\\)', '', full_text)\n",
    "\n",
    "            # Normalize spaces to avoid issues with trailing/extra spaces\n",
    "            cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "\n",
    "            # Remove punctuation after eliminating specific tokens\n",
    "            cleaned_text = re.sub(r'[^\\w\\s]', '', cleaned_text)\n",
    "\n",
    "            # Check if cleaned text is not empty\n",
    "            if cleaned_text:\n",
    "                # Skip if the new verse is identical to the previous one\n",
    "                if cleaned_text == previous_verse:\n",
    "                    continue  # Skip duplicate verse\n",
    "                \n",
    "                # Update the previous verse tracker\n",
    "                previous_verse = cleaned_text\n",
    "\n",
    "                # Split into individual words\n",
    "                tokens = cleaned_text.split()\n",
    "                for token in tokens:\n",
    "                    # Skip words containing digits\n",
    "                    if not re.search(r'\\d', token):\n",
    "                        words.append([token, \"\", \"\"])  # Add empty 'pos' and 'lemma'\n",
    "                # Add an end-of-segment marker for each element\n",
    "                words.append([\"$\", \"\", \"\"])\n",
    "\n",
    "    # Convert to DataFrame and save as TSV\n",
    "    df = pd.DataFrame(words, columns=[\"word\", \"pos\", \"lemma\"])\n",
    "    df.to_csv(tsv_filepath, index=False, header=True, encoding='utf-8', sep=\"\\t\")\n",
    "    print(df.head(20))\n",
    "\n",
    "# Run the function\n",
    "process_xml_to_tsv('../sidrac/sidrac_cdrom.xml', '../sidrac/sidrac_clean_double.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a9742f",
   "metadata": {},
   "source": [
    "Use galahad now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4663670d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing words: 100%|████████████████| 91211/91211 [00:01<00:00, 78626.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete! XML file saved as: ../sidrac/sidrac.xml\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from lxml import etree\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define input and output file paths\n",
    "input_file = \"../sidrac/sidrac_galahad.tsv\"\n",
    "output_file = \"../sidrac/sidrac.xml\"\n",
    "\n",
    "# Function to convert TSV to XML\n",
    "def convert_tsv_to_xml(tsv_filepath, xml_filepath):\n",
    "    \"\"\"Convert a TSV file into an XML document.\"\"\"\n",
    "    df = pd.read_csv(tsv_filepath, sep=\"\\t\", dtype=str).fillna(\"\")  # Read TSV, fill empty values with \"\"\n",
    "\n",
    "    root = etree.Element(\"text\", id=\"sidrac\")  # Root element <text id=\"sidrac\">\n",
    "\n",
    "    line_tokens, line_lemmas, line_words = [], [], []  # Buffers for line data\n",
    "    line_number = 1  # Verse/line counter\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing words\"):\n",
    "        form, pos, lemma = row[\"form\"], row[\"pos\"], row[\"lemma\"]  # Extract columns\n",
    "\n",
    "        if form == \"$\":  # End of a verse → Create <l> element\n",
    "            if line_tokens:\n",
    "                l_element = etree.SubElement(\n",
    "                    root, \"l\",\n",
    "                    n=str(line_number),\n",
    "                    tokens=\" \".join(line_tokens),\n",
    "                    lemmas=\" \".join(line_lemmas)\n",
    "                )\n",
    "                for w in line_words:\n",
    "                    l_element.append(w)\n",
    "\n",
    "                # Reset buffers for the next verse\n",
    "                line_tokens, line_lemmas, line_words = [], [], []\n",
    "                line_number += 1\n",
    "        else:\n",
    "            # Create <w> element\n",
    "            w_element = etree.Element(\"w\")\n",
    "            form_el = etree.SubElement(w_element, \"form\")\n",
    "            form_el.text = form\n",
    "\n",
    "            lemma_el = etree.SubElement(w_element, \"lemma\")\n",
    "            lemma_el.text = lemma\n",
    "\n",
    "            pos_el = etree.SubElement(w_element, \"pos\")\n",
    "            pos_el.text = pos\n",
    "\n",
    "            # Append word data\n",
    "            line_tokens.append(form)\n",
    "            line_lemmas.append(lemma)\n",
    "            line_words.append(w_element)\n",
    "\n",
    "    # Save XML file\n",
    "    tree = etree.ElementTree(root)\n",
    "    tree.write(xml_filepath, encoding=\"utf-8\", xml_declaration=True, pretty_print=True)\n",
    "\n",
    "    print(f\"Conversion complete! XML file saved as: {xml_filepath}\")\n",
    "\n",
    "# Run conversion\n",
    "convert_tsv_to_xml(input_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
